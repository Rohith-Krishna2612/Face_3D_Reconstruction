{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f2aeb7b",
   "metadata": {},
   "source": [
    "# üéØ Face Restoration Training - Kaggle Edition\n",
    "\n",
    "**For Hybrid Training: Kaggle + Colab + Local**\n",
    "\n",
    "All checkpoints auto-sync to Google Drive - seamlessly switch between platforms!\n",
    "\n",
    "**Setup:** \n",
    "1. Enable GPU: Settings ‚Üí Accelerator ‚Üí GPU T4 x2  \n",
    "2. Enable Internet: Settings ‚Üí Internet ‚Üí On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d573b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n‚úÖ PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffbb0ee",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac61b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/kaggle/working')\n",
    "\n",
    "# Remove previous clone if exists\n",
    "!rm -rf Face_3D_Reconstruction\n",
    "\n",
    "!git clone https://github.com/Rohith-Krishna2612/Face_3D_Reconstruction.git\n",
    "os.chdir('Face_3D_Reconstruction')\n",
    "\n",
    "print(\"‚úÖ Repository cloned!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c5892",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b36be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies first\n",
    "!pip install -r requirements.txt -q\n",
    "\n",
    "# Force downgrade NumPy and protobuf AFTER requirements.txt\n",
    "!pip install --force-reinstall numpy==1.26.4 protobuf==4.25.3 -q\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")\n",
    "print(\"‚ö†Ô∏è Restart kernel if imports still fail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc194b83",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Setup FFHQ Dataset\n",
    "\n",
    "**Add dataset:**\n",
    "- Click \"Add Data\" button (right sidebar)\n",
    "- Search: \"flickrfaceshq-dataset-ffhq\"\n",
    "- Click \"Add\" on dataset by arnaud58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31988877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "kaggle_dataset = '/kaggle/input/flickrfaceshq-dataset-ffhq'\n",
    "\n",
    "if os.path.exists(kaggle_dataset):\n",
    "    for root, dirs, files in os.walk(kaggle_dataset):\n",
    "        if 'thumbnails128x128' in root or 'thumbnails' in root:\n",
    "            continue  # Skip thumbnail folders\n",
    "        if len(files) > 1000:\n",
    "            DATASET_PATH = root\n",
    "            print(f\"‚úÖ Dataset: {root}\")\n",
    "            print(f\"‚úÖ Images: {len(files)}\")\n",
    "            break\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found!\")\n",
    "    print(\"üìù Add it via: Add Data ‚Üí 'flickrfaceshq-dataset-ffhq'\")\n",
    "    DATASET_PATH = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41076d1c",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Create Dataset Symlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217a92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "if DATASET_PATH:\n",
    "    if os.path.exists('data/ffhq'):\n",
    "        os.unlink('data/ffhq')\n",
    "    os.symlink(DATASET_PATH, 'data/ffhq', target_is_directory=True)\n",
    "    print(f\"‚úÖ Symlink created\")\n",
    "    print(f\"‚úÖ Images: {len(os.listdir('data/ffhq'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420527da",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Configure Checkpoint Paths\n",
    "\n",
    "**Note:** Skipping Drive mounting for Kaggle - checkpoints save locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4df2a4b",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Start Training üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5c98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training (will auto-resume if checkpoints exist)\n",
    "!python quick_train.py --epochs 100 --max-samples 10000 --yes\n",
    "\n",
    "print(\"\\nüéâ Training complete!\")\n",
    "print(\"‚úÖ Checkpoints saved locally\")\n",
    "print(\"üí° Download checkpoints and upload to Drive for hybrid training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0fc085",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ View Training Progress (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c29276",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/codeformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d3ab40",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Download Checkpoints (Optional)\n",
    "\n",
    "If you want to use checkpoints locally or in Colab, download them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "checkpoint_dir = 'checkpoints/codeformer'\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.endswith('.pth')]\n",
    "    \n",
    "    print(f\"üì• Available checkpoints ({len(checkpoints)}):\")\n",
    "    for cp in checkpoints:\n",
    "        cp_path = os.path.join(checkpoint_dir, cp)\n",
    "        size_mb = os.path.getsize(cp_path) / 1024**2\n",
    "        print(f\"\\n   {cp} ({size_mb:.1f} MB)\")\n",
    "        display(FileLink(cp_path))\n",
    "else:\n",
    "    print(\"‚ùå No checkpoints found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ebf8a3",
   "metadata": {},
   "source": [
    "## ‚úÖ After Training - Upload to Drive\n",
    "\n",
    "**To sync with Colab/Local:**\n",
    "\n",
    "1. **Download checkpoints** from notebook output (last cell)\n",
    "2. **Upload to Google Drive** manually:\n",
    "   - Go to `MyDrive/Face_3D_Reconstruction/checkpoints/codeformer/`\n",
    "   - Upload the `.pth` files\n",
    "\n",
    "**Or simpler:** Just use Kaggle for one platform, Colab for another. Download the best checkpoint at the end and use it locally for your web app!\n",
    "\n",
    "**Training estimate:** 30 hrs/week = ~7 epochs/week üöÄ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
